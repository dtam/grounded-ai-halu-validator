# Overview

| Developed by | GroundedAI |
| --- | --- |
| Date of development | October 9, 2024 |
| Validator type | Hallucination |
| Blog |  |
| License | Apache 2 |
| Input/Output | Output |

## Description

### Intended Use
This validator is a template for creating other validators, but for demonstrative purposes it ensures that a generated output is the literal `pass`.

### Requirements

* Dependencies:
	- guardrails-ai>=0.4.0

* Foundation model access keys:
	- OPENAI_API_KEY

## Installation

```bash
$ guardrails hub install hub://guardrails/validator_template
```

## Usage Examples

### Validating string output via Python

In this example, we apply the validator to a string output generated by an LLM.

```python
# Import Guard and Validator
from guardrails.hub import ValidatorTemplate
from guardrails import Guard

# Setup Guard
guard = Guard().use(
    ValidatorTemplate
)

guard.validate("pass")  # Validator passes
guard.validate("fail")  # Validator fails
```

### Validating JSON output via Python

In this example, we apply the validator to a string field of a JSON output generated by an LLM.

```python
# Import Guard and Validator
from pydantic import BaseModel, Field
from guardrails.hub import ValidatorTemplate
from guardrails import Guard

# Initialize Validator
val = ValidatorTemplate()

# Create Pydantic BaseModel
class Process(BaseModel):
		process_name: str
		status: str = Field(validators=[val])

# Create a Guard to check for valid Pydantic output
guard = Guard.from_pydantic(output_class=Process)

# Run LLM output generating JSON through guard
guard.parse("""
{
	"process_name": "templating",
	"status": "pass"
}
""")
```

# API Reference

**`__init__(self, on_fail="noop")`**
<ul>
Initializes a new instance of the ValidatorTemplate class.

**Parameters**
- **`arg_1`** *(str)*: A placeholder argument to demonstrate how to use init arguments.
- **`arg_2`** *(str)*: Another placeholder argument to demonstrate how to use init arguments.
- **`on_fail`** *(str, Callable)*: The policy to enact when a validator fails.  If `str`, must be one of `reask`, `fix`, `filter`, `refrain`, `noop`, `exception` or `fix_reask`. Otherwise, must be a function that is called when the validator fails.
</ul>
<br/>

**`validate(self, value, metadata) -> ValidationResult`**
<ul>
Validates the given `value` using the rules defined in this validator, relying on the `metadata` provided to customize the validation process. This method is automatically invoked by `guard.parse(...)`, ensuring the validation logic is applied to the input data.

Note:

1. This method should not be called directly by the user. Instead, invoke `guard.parse(...)` where this method will be called internally for each associated Validator.
2. When invoking `guard.parse(...)`, ensure to pass the appropriate `metadata` dictionary that includes keys and values required by this validator. If `guard` is associated with multiple validators, combine all necessary metadata into a single dictionary.

**Parameters**
- **`value`** *(Any)*: The input value to validate.
- **`metadata`** *(dict)*: A dictionary containing metadata required for validation. Keys and values must match the expectations of this validator.
    
    
    | Key | Type | Description | Default |
    | --- | --- | --- | --- |
    | `key1` | String | Description of key1's role. | N/A |
</ul>

# Overview

| Developed by | GroundedAI |
| --- | --- |
| Date of development | October 9, 2024 |
| Validator type | Hallucination |
| Blog |  |
| License | Apache 2 |
| Input/Output | Output |

## Description

### Intended Use
This validator uses a fine-tuned language model to detect hallucinations in AI-generated responses. It evaluates whether a given response is grounded in the provided context or if it contains factually incorrect or nonsensical information.

### Requirements

* Dependencies:
	- guardrails-ai>=0.4.0
	- torch
	- transformers
	- peft
	- jinja2

* Foundation model access:
	- Internet connection to download the required models

## Installation

```bash
$ guardrails hub install hub://guardrails/grounded-ai-hallucination
```

## Usage Examples

### Validating string output via Python

In this example, we apply the validator to check if an AI-generated response is a hallucination.

```python
from guardrails.hub import GroundedAIHallucination
from guardrails import Guard

guard = Guard().use(GroundedAIHallucination(quant=True))

guard.validate({
    "query": "What is the capital of France?",
    "response": "The capital of France is London.",
    "reference": "The capital of France is Paris."
}) 

>>> # Validator fails

guard.validate({
    "query": "What is the capital of France?",
    "response": "The capital of France is Paris.",
    "reference": "The capital of France is Paris."
}) 

>>> # Validator passes
```

# API Reference

**`__init__(self, quant: bool, base_prompt: Optional[str] = HALLUCINATION_EVAL_BASE)`**
<ul>
Initializes a new instance of the GroundedAIHallucination class.

**Parameters**
- **`quant`** *(bool)*: Whether to use quantization for the model.
- **`base_prompt`** *(Optional[str])*: The base prompt template for hallucination evaluation. Defaults to HALLUCINATION_EVAL_BASE.
- **`on_fail`** *(str, Callable)*: The policy to enact when a validator fails. If `str`, must be one of `reask`, `fix`, `filter`, `refrain`, `noop`, `exception` or `fix_reask`. Otherwise, must be a function that is called when the validator fails.
</ul>
<br/>

**`validate(self, value: Dict, metadata: Dict = {}) -> ValidationResult`**
<ul>
Validates whether the given response is a hallucination based on the provided query and reference.

**Parameters**
- **`value`** *(Dict)*: A dictionary containing the following keys:
  - `query` (str): The original question or prompt.
  - `response` (str): The AI-generated response to validate.
  - `reference` (str): Optional reference information for fact-checking.
- **`metadata`** *(dict)*: Additional metadata (not used in this validator).

**Returns**
- **`ValidationResult`**: Indicates whether the validation passed or failed.
</ul>